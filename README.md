# Enhanced Blind Detection System

A real-time object detection system designed to assist visually impaired users with navigation through audio announcements and visual feedback.

## Features

ğŸ¯ **Real-time Object Detection** - Uses YOLOv8 for accurate object detection
ğŸ‘ï¸ **Visual Interface** - Live camera feed with detection boxes and labels  
ğŸ”Š **Audio Announcements** - Intelligent text-to-speech guidance
ğŸ“ **Spatial Analysis** - Distance and position information
âš¡ **GPU Acceleration** - CUDA support for better performance
ğŸ›ï¸ **Multiple Scenarios** - Indoor, outdoor, and performance-optimized modes

# Colaborator
**Aviral Rai 
**Mohammad Faiz Khan 

## Quick Start

1. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Run the Visual Camera System**
   ```bash
   # Start visual detection with camera popup window
   python run_visual_demo.py --scenario indoor
   
   # Alternative scenarios
   python run_visual_demo.py --scenario outdoor
   python run_visual_demo.py --scenario high_performance
   ```

3. **Camera Window Controls**
   - **'q'** - Quit and close camera window
   - **'s'** - Save screenshot of current view
   - **'z'** - Toggle zone lines (shows detection areas)
   - **'f'** - Toggle FPS display (shows performance)

   > ğŸ’¡ **Tip**: Press 's' while the camera is running to save a screenshot to the project folder

## What You'll See

When you run the system, a **camera window will popup** showing:
- âœ… **Live camera feed** from your webcam
- ğŸŸ¢ **Green boxes** around far objects 
- ğŸŸ¡ **Orange boxes** around medium distance objects
- ğŸ”´ **Red boxes** around close objects (warning!)
- ğŸ“ **Labels** showing object name and distance
- ğŸ¯ **Crosshair** in center for navigation reference
- ğŸ“Š **Performance metrics** (if enabled with 'f' key)

### Screenshot Example

![Enhanced Blind Detection System in Action](Screenshot%202025-07-23%20133559.png)

*Example showing the camera interface with object detection boxes, distance labels, and visual indicators*

## System Requirements

- Python 3.8+
- **Webcam or camera device** (required for visual interface)
- Windows/Linux/macOS
- Optional: NVIDIA GPU with CUDA for better performance

## Audio Feedback

The system provides **intelligent audio announcements**:
- ğŸ”´ **Urgent warnings** for objects directly ahead and close
- ğŸŸ¡ **Caution alerts** for objects to the side or medium distance  
- ğŸŸ¢ **Information** about far objects and general navigation
- ğŸ¯ **Spatial guidance** with left/center/right positioning

## Configuration

The system uses `config.yaml` with built-in scenarios:
- **Indoor** - Optimized for indoor navigation
- **Outdoor** - Better for outdoor environments  
- **High Performance** - Uses more resources for better accuracy
- **Low Resource** - Lighter processing for older computers

## Usage Examples

```bash
# Most common usage - indoor camera view
python run_visual_demo.py --scenario indoor

# For outdoor use
python run_visual_demo.py --scenario outdoor

# High performance (if you have a good computer/GPU)
python run_visual_demo.py --scenario high_performance

# Audio only mode (no camera window)
python run_app.py --audio-only
```

## Project Structure

```
blind-cap-object-detection/
â”œâ”€â”€ src/                          # Core application modules
â”‚   â”œâ”€â”€ main.py                   # Main application controller
â”‚   â”œâ”€â”€ detector.py               # YOLOv8 object detection
â”‚   â”œâ”€â”€ visual_interface.py       # Camera window and visual overlay
â”‚   â”œâ”€â”€ audio.py                  # Text-to-speech announcements
â”‚   â”œâ”€â”€ spatial.py                # Distance and position analysis
â”‚   â””â”€â”€ frame_processor.py        # Camera handling
â”œâ”€â”€ run_visual_demo.py            # â­ Main script to run camera system
â”œâ”€â”€ run_app.py                    # Alternative runner (audio-only mode)
â”œâ”€â”€ config.yaml                   # Configuration settings
â”œâ”€â”€ yolov8n.pt                    # Pre-trained AI model
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## License

MIT License - see LICENSE file for details
